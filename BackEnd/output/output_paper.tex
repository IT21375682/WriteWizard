\documentclass[conference]{IEEEtran}
\usepackage{graphicx}

\title{dharani paper}

\author{

  
    
      \IEEEauthorblockN{krithy}
      \IEEEauthorblockA{
        SLIIT \\
        KRITHU@gmail.com
      }
    
      \IEEEauthorblockN{shandeep}
      \IEEEauthorblockA{
        SLIIT \\
        shandeep@gmail.com
      }
    
    
    
  

}

\begin{document}

\maketitle

\begin{abstract}
Academic writing and research paper formatting have traditionally been manual, time-consuming processes, requiring strict adherence to publication standards such as IEEE. The emergence of AI-driven writing assistants and automated formatting tools has introduced significant improvements, yet current solutions remain fragmented, lacking a comprehensive system that seamlessly integrates academic writing enhancement, structural compliance, and LaTeX-based formatting.
\end{abstract}




  \section{Introduction}
  Existing AI-powered tools such as Grammarly, Hemingway Editor, and LanguageTool offer basic grammar checking, tone adjustments, and readability enhancements. These tools assist in refining sentence structure and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.

  
    
      \subsection{ssssssssss}
      Existing AI-powered tools such as Grammarly, Hemingway Editor, and LanguageTool offer basic grammar checking, tone adjustments, and readability enhancements. These tools assist in refining sentence structure and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{..//uploads/1740310754251.jpg}
\caption{galaxy}
\end{figure}


    
  



  \section{Literature Review}
  Existing AI-powered tools such as Grammarly, Hemingway Editor, and LanguageTool offer basic grammar checking, tone adjustments, and readability enhancements. These tools assist in refining sentence structure and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.






  \section{Results / Discussion}
  ucture and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.ucture and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{..//uploads/1740312155867.jpg}
\caption{shan}
\end{figure}









  

  

  
    \section{Related Work / Literature Review}
    ucture and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.
ucture and improving clarity but lack domain-specific academic writing capabilities tailored to IEEE-style publications. Furthermore, these tools do not offer technical writing enhancements, citation standardization, or logical coherence validation, which are critical for research papers.
Large language models (LLMs) such as GPT-4, BERT, and T5 have demonstrated remarkable performance in natural language processing (NLP) tasks, including text summarization, paraphrasing, and content generation. However, these models are not optimized for research writing since they do not enforce IEEE academic tone, passive voice structuring, or precise technical vocabulary usage. The Llama 2-7B model, used in this research, bridges this gap by refining informal text into structured, IEEE-compliant academic writing while maintaining logical flow, coherence, and domain-specific technical accuracy.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{..//uploads/1740312088464.jpg}
\caption{shandeep}
\end{figure}


    
  

  




\begin{thebibliography}{1}

  
    \bibitem{ref-1740225905483}
    
  
    \bibitem{ref-1740311604268}
    
  

\end{thebibliography}

\end{document}
